{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "92cYIeQF0bAQ"
   },
   "source": [
    "# Segmentation of Indian Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gG_10XW0bAR"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from PIL import Image, ImageDraw\n",
    "from PIL import ImagePath\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bl2voXpM0bAW"
   },
   "source": [
    "<pre>\n",
    "1. You can download the data from this link, and extract it\n",
    "\n",
    "2. All your data will be in the folder \"data\" \n",
    "\n",
    "3. Inside the data you will be having two folders\n",
    "\n",
    "|--- data\n",
    "|-----| ---- images\n",
    "|-----| ------|----- Scene 1\n",
    "|-----| ------|--------| ----- Frame 1 (image 1)\n",
    "|-----| ------|--------| ----- Frame 2 (image 2)\n",
    "|-----| ------|--------| ----- ...\n",
    "|-----| ------|----- Scene 2\n",
    "|-----| ------|--------| ----- Frame 1 (image 1)\n",
    "|-----| ------|--------| ----- Frame 2 (image 2)\n",
    "|-----| ------|--------| ----- ...\n",
    "|-----| ------|----- .....\n",
    "|-----| ---- masks\n",
    "|-----| ------|----- Scene 1\n",
    "|-----| ------|--------| ----- json 1 (labeled objects in image 1)\n",
    "|-----| ------|--------| ----- json 2 (labeled objects in image 1)\n",
    "|-----| ------|--------| ----- ...\n",
    "|-----| ------|----- Scene 2\n",
    "|-----| ------|--------| ----- json 1 (labeled objects in image 1)\n",
    "|-----| ------|--------| ----- json 2 (labeled objects in image 1)\n",
    "|-----| ------|--------| ----- ...\n",
    "|-----| ------|----- .....\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWCQ4I4d0bAX"
   },
   "source": [
    "# Task 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4owX5YO0bAY"
   },
   "source": [
    "## 1. Get all the file name and corresponding json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-Q8onrE0bAZ"
   },
   "outputs": [],
   "source": [
    "root_dir = 'data'\n",
    "def return_file_names_df(root_dir):\n",
    "    # write the code that will create a dataframe with two columns ['images', 'json']\n",
    "    # the column 'image' will have path to images\n",
    "    # the column 'json' will have path to json files\n",
    "    data_df = []\n",
    "    \n",
    "    images, mask = os.listdir(root_dir)\n",
    "    \n",
    "    for scene in os.listdir(root_dir+'/'+images):\n",
    "        image_frame = os.listdir(root_dir+'/'+images+'/'+scene)\n",
    "        image_frame = list(map(lambda x: root_dir+'/'+images+'/'+scene+'/'+x, image_frame))\n",
    "        image_frame.sort()\n",
    "        \n",
    "        mask_frame = os.listdir(root_dir+'/'+mask+'/'+scene)\n",
    "        mask_frame = list(map(lambda x: root_dir+'/'+mask+'/'+scene+'/'+x, mask_frame))\n",
    "        mask_frame.sort()\n",
    "        \n",
    "        data_df.extend(list(zip(image_frame, mask_frame)))\n",
    "\n",
    "    data_df = pd.DataFrame(data_df, columns=['image', 'json'])\n",
    "    return data_df\n",
    "# return_file_names_df(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em4n2bW10bAc",
    "outputId": "bbc97e7a-e093-40e3-b5e8-17947816146e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/images/201/frame0029_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame0029_gtFine_polygons.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/images/201/frame0299_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame0299_gtFine_polygons.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/images/201/frame0779_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame0779_gtFine_polygons.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/images/201/frame1019_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame1019_gtFine_polygons.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/images/201/frame1469_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame1469_gtFine_polygons.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image  \\\n",
       "0  data/images/201/frame0029_leftImg8bit.jpg   \n",
       "1  data/images/201/frame0299_leftImg8bit.jpg   \n",
       "2  data/images/201/frame0779_leftImg8bit.jpg   \n",
       "3  data/images/201/frame1019_leftImg8bit.jpg   \n",
       "4  data/images/201/frame1469_leftImg8bit.jpg   \n",
       "\n",
       "                                           json  \n",
       "0  data/mask/201/frame0029_gtFine_polygons.json  \n",
       "1  data/mask/201/frame0299_gtFine_polygons.json  \n",
       "2  data/mask/201/frame0779_gtFine_polygons.json  \n",
       "3  data/mask/201/frame1019_gtFine_polygons.json  \n",
       "4  data/mask/201/frame1469_gtFine_polygons.json  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = return_file_names_df(root_dir)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uof88SJW0bAf"
   },
   "source": [
    "> If you observe the dataframe, we can consider each row as single data point, where first feature is image and the second feature is corresponding json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjMprsim0bAg"
   },
   "outputs": [],
   "source": [
    "def grader_1(data_df):\n",
    "    for i in data_df.values:\n",
    "        if not (path.isfile(i[0]) and path.isfile(i[1]) and i[0][12:i[0].find('_')]==i[1][10:i[1].find('_')]):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fvgVQWF0bAj",
    "outputId": "8ed653b4-ee69-466e-ae08-1897fd3a8316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader_1(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ijL77Y10bAl",
    "outputId": "df272242-749a-410e-c29a-0fc761a0db39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4008, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB2-yrRV0bAo"
   },
   "source": [
    "## 2. Structure of sample Json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DcqXYpEI0bAp"
   },
   "source": [
    "<img src='https://i.imgur.com/EfR5KmI.png' width=\"200\" height=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97ZcwNbr0bAp"
   },
   "source": [
    "* Each File will have 3 attributes\n",
    "    * imgHeight: which tells the height of the image\n",
    "    * imgWidth: which tells the width of the image\n",
    "    * objects: it is a list of objects, each object will have multiple attributes,\n",
    "        * label: the type of the object\n",
    "        * polygon: a list of two element lists, representing the coordinates of the polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYrICucM0bAq"
   },
   "source": [
    "#### Compute the unique labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-OYvoA20bAr"
   },
   "source": [
    "Let's see how many unique objects are there in the json file.\n",
    "to see how to get the object from the json file please check <a href='https://www.geeksforgeeks.org/read-json-file-using-python/'>this blog </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        data/mask/201/frame0029_gtFine_polygons.json\n",
       "1        data/mask/201/frame0299_gtFine_polygons.json\n",
       "2        data/mask/201/frame0779_gtFine_polygons.json\n",
       "3        data/mask/201/frame1019_gtFine_polygons.json\n",
       "4        data/mask/201/frame1469_gtFine_polygons.json\n",
       "                            ...                      \n",
       "4003    data/mask/429/frame13262_gtFine_polygons.json\n",
       "4004    data/mask/429/frame13699_gtFine_polygons.json\n",
       "4005    data/mask/429/frame15812_gtFine_polygons.json\n",
       "4006    data/mask/429/frame18062_gtFine_polygons.json\n",
       "4007    data/mask/429/frame18403_gtFine_polygons.json\n",
       "Name: json, Length: 4008, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add = data_df.loc[0, 'json']\n",
    "\n",
    "with open(add) as f:\n",
    "    jsn = json.load(f)\n",
    "\n",
    "unique_labels = set()\n",
    "for j in jsn['objects']:\n",
    "    unique_labels.add(j['label'])\n",
    "    \n",
    "unique_labels\n",
    "\n",
    "data_df.loc[:,'json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5su9envb0bAr"
   },
   "outputs": [],
   "source": [
    "def return_unique_labels(data_df):\n",
    "    # for each file in the column json\n",
    "    #       read and store all the objects present in that file\n",
    "    # compute the unique objects and retrun them\n",
    "    # if open any json file using any editor you will get better sense of it\n",
    "    \n",
    "    unique_labels = set()\n",
    "    for json_link in data_df.loc[:, 'json']:\n",
    "        with open(json_link) as f:\n",
    "            jsn = json.load(f)\n",
    "\n",
    "        for obj in jsn['objects']:\n",
    "            unique_labels.add(obj['label'])\n",
    "\n",
    "    return unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ch8hYKOS0bAu"
   },
   "outputs": [],
   "source": [
    "unique_labels = return_unique_labels(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6mSHuX4Y0bAw"
   },
   "source": [
    "<img src='https://i.imgur.com/L4QH6Tp.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gnbt7MSc0bAw"
   },
   "outputs": [],
   "source": [
    "label_clr = {'road':10, 'parking':20, 'drivable fallback':20,'sidewalk':30,'non-drivable fallback':40,'rail track':40,\\\n",
    "                        'person':50, 'animal':50, 'rider':60, 'motorcycle':70, 'bicycle':70, 'autorickshaw':80,\\\n",
    "                        'car':80, 'truck':90, 'bus':90, 'vehicle fallback':90, 'trailer':90, 'caravan':90,\\\n",
    "                        'curb':100, 'wall':100, 'fence':110,'guard rail':110, 'billboard':120,'traffic sign':120,\\\n",
    "                        'traffic light':120, 'pole':130, 'polegroup':130, 'obs-str-bar-fallback':130,'building':140,\\\n",
    "                        'bridge':140,'tunnel':140, 'vegetation':150, 'sky':160, 'fallback background':160,'unlabeled':0,\\\n",
    "                        'out of roi':0, 'ego vehicle':170, 'ground':180,'rectification border':190,\\\n",
    "                   'train':200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPuuN7UB0bAz",
    "outputId": "d7160c83-f4e0-4515-f315-bf2fad0bf84f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_2(unique_labels):\n",
    "    if (not (set(label_clr.keys())-set(unique_labels))) and len(unique_labels) == 40:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"Flase\")\n",
    "\n",
    "grader_2(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3xmUIzX00bA2"
   },
   "source": [
    "<pre>\n",
    "* here we have given a number for each of object types, if you see we are having 21 different set of objects\n",
    "* Note that we have multiplies each object's number with 10, that is just to make different objects look differently in the segmentation map\n",
    "* Before you pass it to the models, you might need to devide the image array /10.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzUK6FMJ0bA2"
   },
   "source": [
    "## 3. Extracting the polygons from the json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRRcwMw50bA3"
   },
   "outputs": [],
   "source": [
    "def get_poly(file):\n",
    "    # this function will take a file name as argument\n",
    "    \n",
    "    # it will process all the objects in that file and returns\n",
    "    \n",
    "    # label: a list of labels for all the objects label[i] will have the corresponding vertices in vertexlist[i]\n",
    "    # len(label) == number of objects in the image\n",
    "    \n",
    "    # vertexlist: it should be list of list of vertices in tuple formate \n",
    "    # ex: [[(x11,y11), (x12,y12), (x13,y13) .. (x1n,y1n)]\n",
    "    #     [(x21,y21), (x22,y12), (x23,y23) .. (x2n,y2n)]\n",
    "    #      .....\n",
    "    #     [(xm1,ym1), (xm2,ym2), (xm3,ym3) .. (xmn,ymn)]]\n",
    "    # len(vertexlist) == number of objects in the image\n",
    "    \n",
    "    # * note that label[i] and vertextlist[i] are corresponds to the same object, one represents the type of the object\n",
    "    # the other represents the location\n",
    "    \n",
    "    # width of the image\n",
    "    # height of the image\n",
    "    \n",
    "    with open(file) as f:\n",
    "        jsn = json.load(f)\n",
    "        \n",
    "    h = jsn['imgHeight']\n",
    "    w = jsn['imgWidth']\n",
    "    \n",
    "    label = []\n",
    "    vertexlist = []\n",
    "    for obj in jsn['objects']:\n",
    "        if len(obj['polygon'])>=2:\n",
    "            label.append(obj['label'])\n",
    "            vertexlist.append(list(map(tuple, obj['polygon'])))\n",
    "        \n",
    "    return w, h, label, vertexlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlcCswQR0bA5",
    "outputId": "8d522c26-b4e2-4fcb-f71a-2e2d493e60df",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_3(file):\n",
    "    w, h, labels, vertexlist = get_poly(file)\n",
    "    print(len((set(labels)))==18 and len(vertexlist)==227 and w==1920 and h==1080 \\\n",
    "          and isinstance(vertexlist,list) and isinstance(vertexlist[0],list) and isinstance(vertexlist[0][0],tuple) )\n",
    "\n",
    "grader_3('data/mask/201/frame0029_gtFine_polygons.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lw2MH_ua0bA8"
   },
   "source": [
    "## 4. Creating Image segmentations by drawing set of polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLrtu1f80bA8"
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_1= [(\\ (\\cos(\\theta)+1)*9,\\ \\ (sin(\\theta)+1)*6\\ )\\ for\\ \\theta\\ in\\ [ \\frac{i*(2*\\pi)}{side}\\ for\\ i\\ in\\ range(side)]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-O7l9Xfj0bA9",
    "outputId": "54940e05-d61c-4168-a9d7-fb13d786e27c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "[[0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math \n",
    "from PIL import Image, ImageDraw \n",
    "from PIL import ImagePath  \n",
    "side=8\n",
    "x1 = [ ((math.cos(th) + 1) *9, (math.sin(th) + 1) * 6) for th in [i * (2 * math.pi) / side for i in range(side)] ]\n",
    "x2 = [ ((math.cos(th) + 2) *9, (math.sin(th) + 3) *6) for th in [i * (2 * math.pi) / side for i in range(side)] ]\n",
    "\n",
    "img = Image.new(\"RGB\", (28,28))\n",
    "img1 = ImageDraw.Draw(img)\n",
    "# please play with the fill value\n",
    "\n",
    "# writing the first polygon\n",
    "img1.polygon(x1, fill=20)\n",
    "\n",
    "# writing the second polygon\n",
    "img1.polygon(x2, fill=30)\n",
    "\n",
    "img = np.array(img)\n",
    "# note that the filling of the values happens at the channel 1, so we are considering only the first channel here\n",
    "plt.imshow(img[:,:,0])\n",
    "\n",
    "print(img.shape)\n",
    "print(img[:,:,0]//10)\n",
    "\n",
    "im = Image.fromarray(img[:,:,0])\n",
    "im.save(\"test_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnAzJJhq0bBB"
   },
   "outputs": [],
   "source": [
    "def compute_masks(data_df):\n",
    "    # after you have computed the vertexlist plot that polygone in image like this\n",
    "    \n",
    "    # img = Image.new(\"RGB\", (w, h))\n",
    "    # img1 = ImageDraw.Draw(img)\n",
    "    # img1.polygon(vertexlist[i], fill = label_clr[label[i]])\n",
    "    \n",
    "    # after drawing all the polygons that we collected from json file, \n",
    "    # you need to store that image in the folder like this \"data/output/scene/framenumber_gtFine_polygons.png\"\n",
    "    \n",
    "    # after saving the image into disk, store the path in a list\n",
    "    # after storing all the paths, add a column to the data_df['mask'] ex: data_df['mask']= mask_paths\n",
    "    mask_link_list = []\n",
    "    for link in tqdm(data_df.loc[:, 'json']):\n",
    "        w, h, label, vertexlist = get_poly(link)\n",
    "        \n",
    "        img = Image.new(\"RGB\", (w, h))\n",
    "        img1 = ImageDraw.Draw(img)\n",
    "        \n",
    "        for i in range(len(vertexlist)):\n",
    "            img1.polygon(vertexlist[i], fill=label_clr[label[i]])\n",
    "            \n",
    "        img = np.array(img)\n",
    "        im = Image.fromarray(img[:,:,0])\n",
    "        \n",
    "        mask_link = link.replace('mask', 'output').replace('json', 'png')\n",
    "        mask_link_list.append(mask_link)\n",
    "        \n",
    "#         path of directory where the mask image will be saved\n",
    "        path = '/'.join(mask_link.split('/')[0:-1])\n",
    "        \n",
    "#         Creating directory\n",
    "        try:\n",
    "            os.makedirs(path, exist_ok = True)\n",
    "        except OSError as error:\n",
    "            print(\"Directory '%s' can not be created\" % directory)\n",
    "        \n",
    "        im.save(mask_link)\n",
    "        \n",
    "    data_df.loc[:,'mask'] = mask_link_list\n",
    "    return data_df\n",
    "\n",
    "# compute_masks(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4008/4008 [07:29<00:00,  8.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>json</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/images/201/frame0029_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame0029_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame0029_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/images/201/frame0299_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame0299_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame0299_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/images/201/frame0779_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame0779_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame0779_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/images/201/frame1019_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame1019_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame1019_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/images/201/frame1469_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame1469_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame1469_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image  \\\n",
       "0  data/images/201/frame0029_leftImg8bit.jpg   \n",
       "1  data/images/201/frame0299_leftImg8bit.jpg   \n",
       "2  data/images/201/frame0779_leftImg8bit.jpg   \n",
       "3  data/images/201/frame1019_leftImg8bit.jpg   \n",
       "4  data/images/201/frame1469_leftImg8bit.jpg   \n",
       "\n",
       "                                           json  \\\n",
       "0  data/mask/201/frame0029_gtFine_polygons.json   \n",
       "1  data/mask/201/frame0299_gtFine_polygons.json   \n",
       "2  data/mask/201/frame0779_gtFine_polygons.json   \n",
       "3  data/mask/201/frame1019_gtFine_polygons.json   \n",
       "4  data/mask/201/frame1469_gtFine_polygons.json   \n",
       "\n",
       "                                            mask  \n",
       "0  data/output/201/frame0029_gtFine_polygons.png  \n",
       "1  data/output/201/frame0299_gtFine_polygons.png  \n",
       "2  data/output/201/frame0779_gtFine_polygons.png  \n",
       "3  data/output/201/frame1019_gtFine_polygons.png  \n",
       "4  data/output/201/frame1469_gtFine_polygons.png  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = compute_masks(data_df)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqQibTJE0bBO",
    "outputId": "5d3beeea-e62e-4028-e3c3-590e2893ef0b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[  0  10  20  40  50  60  70  80  90 100 120 130 140 150 160]\n",
      "[  0  10  20  40  50  60  70  80  90 100 120 130 140 150 160]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def grader_3():\n",
    "    url = \"https://i.imgur.com/4XSUlHk.png\"\n",
    "    url_response = urllib.request.urlopen(url)\n",
    "    \n",
    "    img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array, -1)\n",
    "    \n",
    "    my_img = cv2.imread('data/output/201/frame0029_gtFine_polygons.png')    \n",
    "    plt.imshow(my_img)\n",
    "    \n",
    "    print((my_img[:,:,0]==img).all())\n",
    "    print(np.unique(img))\n",
    "    print(np.unique(my_img[:,:,0]))\n",
    "    data_df.to_csv('preprocessed_data.csv', index=False)\n",
    "grader_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9RPr0aZ0bBU"
   },
   "source": [
    "# Task 2: Applying Unet to segment the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDRjb4AD0bBV"
   },
   "source": [
    "<pre>\n",
    "* please check the paper: https://arxiv.org/abs/1505.04597\n",
    "\n",
    "* <img src='https://i.imgur.com/rD4yP7J.jpg' width=\"500\">\n",
    "\n",
    "* As a part of this assignment we won't writingt this whole architecture, rather we will be doing transfer learning\n",
    "\n",
    "* please check the library <a hreaf='https://github.com/qubvel/segmentation_models'>https://github.com/qubvel/segmentation_models</a>\n",
    "\n",
    "* You can install it like this \"pip install -U segmentation-models==0.2.1\", even in google colab you can install the    same with \"!pip install -U segmentation-models==0.2.1\" \n",
    "\n",
    "* Check the reference notebook in which we have solved one end to end case study of image forgery detection using same  unet\n",
    "\n",
    "* The number of channels in the output will depend on the number of classes in your data, since we know that we are having 21 classes, the number of channels in the output will also be 21\n",
    "\n",
    "* <strong>This is where we want you to explore, how do you featurize your created segmentation map note that the original map will be of (w, h, 1) and the output will be (w, h, 21) how will you calculate the loss</strong>, you can check the examples in segmentation github\n",
    "\n",
    "* please use the loss function that is used in the refence notebooks\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>json</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/images/201/frame0029_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame0029_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame0029_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/images/201/frame0299_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame0299_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame0299_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/images/201/frame0779_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame0779_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame0779_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/images/201/frame1019_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame1019_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame1019_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/images/201/frame1469_leftImg8bit.jpg</td>\n",
       "      <td>data/mask/201/frame1469_gtFine_polygons.json</td>\n",
       "      <td>data/output/201/frame1469_gtFine_polygons.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image  \\\n",
       "0  data/images/201/frame0029_leftImg8bit.jpg   \n",
       "1  data/images/201/frame0299_leftImg8bit.jpg   \n",
       "2  data/images/201/frame0779_leftImg8bit.jpg   \n",
       "3  data/images/201/frame1019_leftImg8bit.jpg   \n",
       "4  data/images/201/frame1469_leftImg8bit.jpg   \n",
       "\n",
       "                                           json  \\\n",
       "0  data/mask/201/frame0029_gtFine_polygons.json   \n",
       "1  data/mask/201/frame0299_gtFine_polygons.json   \n",
       "2  data/mask/201/frame0779_gtFine_polygons.json   \n",
       "3  data/mask/201/frame1019_gtFine_polygons.json   \n",
       "4  data/mask/201/frame1469_gtFine_polygons.json   \n",
       "\n",
       "                                            mask  \n",
       "0  data/output/201/frame0029_gtFine_polygons.png  \n",
       "1  data/output/201/frame0299_gtFine_polygons.png  \n",
       "2  data/output/201/frame0779_gtFine_polygons.png  \n",
       "3  data/output/201/frame1019_gtFine_polygons.png  \n",
       "4  data/output/201/frame1469_gtFine_polygons.png  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('preprocessed_data.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3206,) (802,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df['image'], data_df['mask'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nehal\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Nehal\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Nehal\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nehal\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Nehal\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Nehal\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a32920475ac0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# we are importing the pretrained unet from the segmentation models\n",
    "# https://github.com/qubvel/segmentation_models\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "# sm.set_framework('tf.keras')\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"u-resnet34\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 512, 512, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 518, 518, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 256, 256, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 256, 256, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 256, 256, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 258, 258, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 128, 128, 64) 0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 128, 128, 64) 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 128, 128, 64) 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 130, 130, 64) 0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 128, 128, 64) 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 128, 128, 64) 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 130, 130, 64) 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 128, 128, 64) 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 64) 0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 128, 128, 64) 256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 128, 128, 64) 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 130, 130, 64) 0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 128, 128, 64) 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 128, 128, 64) 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 130, 130, 64) 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 64) 0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 128, 128, 64) 256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 128, 128, 64) 0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 130, 130, 64) 0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 128, 128, 64) 256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 128, 128, 64) 0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 130, 130, 64) 0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 128, 128, 64) 36864       zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 128, 64) 0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 128, 128, 64) 256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 128, 128, 64) 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 130, 130, 64) 0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 64, 64, 128)  73728       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 64, 64, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 64, 64, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 64, 64, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 64, 64, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 64, 64, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 64, 64, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 64, 64, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 64, 64, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 64, 64, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 64, 64, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 64, 64, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 64, 64, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 64, 64, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 64, 64, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 64, 64, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 66, 66, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 64, 64, 128)  147456      zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 64, 64, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 64, 64, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 66, 66, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 32, 32, 256)  294912      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 32, 32, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 32, 32, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, 34, 34, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 32, 32, 256)  589824      zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 32, 32, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 32, 32, 256)  1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 32, 32, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, 34, 34, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 16, 16, 512)  1179648     zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 16, 16, 512)  2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 16, 16, 512)  0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 16, 16, 512)  131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 512)  0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 16, 16, 512)  2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 16, 16, 512)  0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 16, 16, 512)  2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 16, 16, 512)  0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 512)  0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 16, 16, 512)  2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 16, 16, 512)  0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 16, 16, 512)  2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 16, 16, 512)  0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 16, 16, 512)  2359296     zero_padding2d_34[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 512)  0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 16, 16, 512)  2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 16, 16, 512)  0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsample (UpSamp (None, 32, 32, 512)  0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 768)  0           decoder_stage0_upsample[0][0]    \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv1 (Conv2D)   (None, 32, 32, 256)  1769472     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_bn1 (BatchNormal (None, 32, 32, 256)  1024        decoder_stage0_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu1 (Activatio (None, 32, 32, 256)  0           decoder_stage0_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv2 (Conv2D)   (None, 32, 32, 256)  589824      decoder_stage0_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_bn2 (BatchNormal (None, 32, 32, 256)  1024        decoder_stage0_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu2 (Activatio (None, 32, 32, 256)  0           decoder_stage0_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsample (UpSamp (None, 64, 64, 256)  0           decoder_stage0_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 384)  0           decoder_stage1_upsample[0][0]    \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv1 (Conv2D)   (None, 64, 64, 128)  442368      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_bn1 (BatchNormal (None, 64, 64, 128)  512         decoder_stage1_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu1 (Activatio (None, 64, 64, 128)  0           decoder_stage1_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv2 (Conv2D)   (None, 64, 64, 128)  147456      decoder_stage1_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_bn2 (BatchNormal (None, 64, 64, 128)  512         decoder_stage1_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu2 (Activatio (None, 64, 64, 128)  0           decoder_stage1_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsample (UpSamp (None, 128, 128, 128 0           decoder_stage1_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 192 0           decoder_stage2_upsample[0][0]    \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv1 (Conv2D)   (None, 128, 128, 64) 110592      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_bn1 (BatchNormal (None, 128, 128, 64) 256         decoder_stage2_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu1 (Activatio (None, 128, 128, 64) 0           decoder_stage2_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv2 (Conv2D)   (None, 128, 128, 64) 36864       decoder_stage2_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_bn2 (BatchNormal (None, 128, 128, 64) 256         decoder_stage2_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu2 (Activatio (None, 128, 128, 64) 0           decoder_stage2_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsample (UpSamp (None, 256, 256, 64) 0           decoder_stage2_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           decoder_stage3_upsample[0][0]    \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv1 (Conv2D)   (None, 256, 256, 32) 36864       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_bn1 (BatchNormal (None, 256, 256, 32) 128         decoder_stage3_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu1 (Activatio (None, 256, 256, 32) 0           decoder_stage3_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv2 (Conv2D)   (None, 256, 256, 32) 9216        decoder_stage3_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_bn2 (BatchNormal (None, 256, 256, 32) 128         decoder_stage3_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu2 (Activatio (None, 256, 256, 32) 0           decoder_stage3_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsample (UpSamp (None, 512, 512, 32) 0           decoder_stage3_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv1 (Conv2D)   (None, 512, 512, 16) 4608        decoder_stage4_upsample[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_bn1 (BatchNormal (None, 512, 512, 16) 64          decoder_stage4_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu1 (Activatio (None, 512, 512, 16) 0           decoder_stage4_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv2 (Conv2D)   (None, 512, 512, 16) 2304        decoder_stage4_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_bn2 (BatchNormal (None, 512, 512, 16) 64          decoder_stage4_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu2 (Activatio (None, 512, 512, 16) 0           decoder_stage4_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, 512, 512, 21) 3045        decoder_stage4_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 512, 512, 21) 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,459,054\n",
      "Trainable params: 3,169,960\n",
      "Non-trainable params: 21,289,094\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loading the unet model and using the resnet 34 and initilized weights with imagenet weights\n",
    "# \"classes\" :different types of classes in the dataset\n",
    "model = Unet('resnet34',\n",
    "             encoder_weights='imagenet',\n",
    "             classes=21,\n",
    "             activation='softmax',\n",
    "             encoder_freeze=True,\n",
    "             input_shape=(512,512,3),\n",
    "            )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "# For the assignment choose any 4 augumentation techniques\n",
    "# check the imgaug documentations for more augmentations\n",
    "aug2 = iaa.Fliplr(1)\n",
    "aug3 = iaa.Flipud(1)\n",
    "aug4 = iaa.Emboss(alpha=(1), strength=1)\n",
    "aug5 = iaa.DirectedEdgeDetect(alpha=(0.8), direction=(1.0))\n",
    "aug6 = iaa.Sharpen(alpha=(1.0), lightness=(1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     14
    ]
   },
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        if i==1:\n",
    "            plt.imshow(image, cmap='gray', vmax=1, vmin=0)\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def normalize_image(mask):\n",
    "    mask = mask/255\n",
    "    return mask\n",
    "\n",
    "class Dataset:\n",
    "    # we will be modifying this CLASSES according to your data/problems\n",
    "    CLASSES = ['road', 'parking_drivable_fallback', 'sidewalk', 'non_drivable_fallback_rail_track', 'person_animal', 'rider', \n",
    "           'motorcycle_bicycle', 'autorickshaw_car', 'truck_bus_vehicle_fallback_trailer_caravan', 'curb_wall',\n",
    "           'fence_guard_rail', 'billboard_traffic_sign_traffic_light', 'pole_polegroup_obs_str_bar_fallback',\n",
    "           'building_bridge_tunnel', 'vegetation', 'sky_fallback_background', 'unlabeled_out_of_roi', 'ego_vehicle', \n",
    "           'ground', 'rectification_border', 'train']\n",
    "    \n",
    "    # the parameters needs to changed based on your requirements\n",
    "    # here we are collecting the file_names because in our dataset, both our images and maks will have same file name\n",
    "    # ex: fil_name.jpg   file_name.mask.jpg\n",
    "    def __init__(self, image, mask, classes):\n",
    "        \n",
    "        # the paths of images\n",
    "        self.images_fps = image\n",
    "        \n",
    "        # the paths of segmentation images\n",
    "        self.masks_fps = mask\n",
    "        \n",
    "        # giving labels for each class\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i], cv2.IMREAD_UNCHANGED)\n",
    "        image = cv2.resize(image, (512,512))\n",
    "        \n",
    "        mask  = cv2.imread(self.masks_fps[i], cv2.IMREAD_UNCHANGED)\n",
    "        mask = cv2.resize(mask, (512,512))\n",
    "        \n",
    "        image_mask = normalize_image(mask)\n",
    "\n",
    "        image_masks = [(image_mask == v) for v in self.class_values]\n",
    "        image_mask = np.stack(image_masks, axis=-1).astype('float')\n",
    "   \n",
    "        a = np.random.uniform()\n",
    "        if a<0.2:\n",
    "            image = aug2.augment_image(image)\n",
    "            image_mask = aug2.augment_image(image_mask)\n",
    "        elif a<0.4:\n",
    "            image = aug3.augment_image(image)\n",
    "            image_mask = aug3.augment_image(image_mask)\n",
    "        elif a<0.6:\n",
    "            image = aug4.augment_image(image)\n",
    "            image_mask = aug4.augment_image(image_mask)\n",
    "        elif a<0.8:\n",
    "            image = aug5.augment_image(image)\n",
    "            image_mask = image_mask\n",
    "        else:\n",
    "            image = aug6.augment_image(image)\n",
    "            image_mask = aug6.augment_image(image_mask)\n",
    "            \n",
    "        return image, image_mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_fps)\n",
    "    \n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        return tuple(batch)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for train images\n",
    "CLASSES = ['road', 'parking_drivable_fallback', 'sidewalk', 'non_drivable_fallback_rail_track', 'person_animal', 'rider', \n",
    "           'motorcycle_bicycle', 'autorickshaw_car', 'truck_bus_vehicle_fallback_trailer_caravan', 'curb_wall',\n",
    "           'fence_guard_rail', 'billboard_traffic_sign_traffic_light', 'pole_polegroup_obs_str_bar_fallback',\n",
    "           'building_bridge_tunnel', 'vegetation', 'sky_fallback_background', 'unlabeled_out_of_roi', 'ego_vehicle', \n",
    "           'ground', 'rectification_border', 'train']\n",
    "\n",
    "train_dataset = Dataset(X_train, y_train, classes=CLASSES)\n",
    "test_dataset  = Dataset(X_test, y_test, classes=CLASSES)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/qubvel/segmentation_models\n",
    "import segmentation_models as sm\n",
    "from segmentation_models.metrics import iou_score\n",
    "from segmentation_models import Unet\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "focal_loss = sm.losses.cce_dice_loss\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss \n",
    "# or total_loss = sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "model.compile(optim, focal_loss, metrics=[iou_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 3)\n",
      "(1, 512, 512, 21)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader[8][0].shape)\n",
    "print(train_dataloader[8][1].shape)\n",
    "\n",
    "# assert train_dataloader[0][0].shape == (BATCH_SIZE, 512, 512, 3)\n",
    "# assert train_dataloader[0][1].shape == (BATCH_SIZE, 512, 512, 21)\n",
    "\n",
    "# define callbacks for learning rate scheduling and best checkpoints saving\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, \\\n",
    "                                       mode='min', monitor='val_iou_score'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_iou_score', min_lr=0.000001, patience=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  86/3206 [..............................] - ETA: 5:02:05 - loss: 1.0003 - iou_score: 1.3578e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8713943d051a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model.fit_generator(train_dataloader,\n\u001b[0;32m      2\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#                               validation_data=test_dataloader,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#                               callbacks=callbacks,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_dataloader,\n",
    "                              steps_per_epoch=len(train_dataloader),\n",
    "                              epochs=1,\n",
    "#                               validation_data=test_dataloader,\n",
    "#                               callbacks=callbacks,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-net = 0.5+ iou\n",
    "# Canet = 0.4+ iou\n",
    "# Please use tensorflow version 2.2.0 and keras version 2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrVV7zW60bBW"
   },
   "source": [
    "### Task 2.1: Dice loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zzYwXRi0bBW"
   },
   "source": [
    "<pre>\n",
    "* Explain the Dice loss\n",
    "* 1. Write the formualtion\n",
    "* 2. Range of the loss function\n",
    "* 3. Interpretation of loss function\n",
    "* 4. Write your understanding of the loss function, how does it helps in segmentation\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akXZdZBx0bBX"
   },
   "source": [
    "### Task 2.2: Training Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5bKBqDn0bBX"
   },
   "source": [
    "\n",
    "<pre>\n",
    "* Split the data into 80:20.\n",
    "* Train the UNET on the given dataset and plot the train and validation loss.\n",
    "* As shown in the reference notebook plot 20 images from the test data along with its segmentation map, predicted map.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTtIHDSf0bBY"
   },
   "source": [
    "# Task 3: Training CANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lM6PTaqo0bBY",
    "outputId": "d6d44dc2-2471-4368-ecad-204a26be17ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Multiply\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0DIdIxO0bBb"
   },
   "source": [
    "* as a part of this assignment we will be implementing the architecture based on this paper https://arxiv.org/pdf/2002.12041.pdf\n",
    "* We will be using the custom layers concept that we used in seq-seq assignment\n",
    "* You can devide the whole architecture can be devided into two parts\n",
    "    1. Encoder\n",
    "    2. Decoder\n",
    "    <img src='https://i.imgur.com/prH3Mno.png' width=\"600\">\n",
    "* Encoder:\n",
    "    * The first step of the encoder is to create the channel maps [$C_1$, $C_2$, $C_3$, $C_4$]\n",
    "    * $C_1$ width and heigths are 4x times less than the original image\n",
    "    * $C_2$ width and heigths are 8x times less than the original image\n",
    "    * $C_3$ width and heigths are 8x times less than the original image\n",
    "    * $C_4$ width and heigths are 8x times less than the original image\n",
    "    * <i>you can reduce the dimensions by using stride parameter</i>.\n",
    "    * [$C_1$, $C_2$, $C_3$, $C_4$] are formed by applying a \"conv block\" followed by $k$ number of \"identity block\". i.e the $C_k$ feature map will single \"conv block\" followed by $k$ number of \"identity blocks\".\n",
    "    <table>\n",
    "    <tr><td><img src=\"https://i.imgur.com/R8Gdypo.png\" width=\"300\"></td>\n",
    "        <td><img src=\"https://i.imgur.com/KNunjQK.png\" width=\"250\"></td></tr>\n",
    "    </table>\n",
    "    * <strong>The conv block and identity block of $C_1$</strong>: the number filters in the covolutional layers will be $[4,4,8]$ and the number of filters in the parallel conv layer will also be $8$.\n",
    "    * <strong>The conv block and identity block of $C_2$</strong>: the number filters in the covolutional layers will be $[8,8,16]$ and the number of filters in the parallel conv layer will also be $16$.\n",
    "    * <strong>The conv block and identity block of $C_3$</strong>: the number filters in the covolutional layers will be $[16,16,32]$ and the number of filters in the parallel conv layer will also be $32$.\n",
    "    * <strong>The conv block and identity block of $C_4$</strong>: the number filters in the covolutional layers will be $[32,32,64]$ and the number of filters in the parallel conv layer will also be $64$.\n",
    "    * Here $\\oplus$ represents the elementwise sum\n",
    "    <br>\n",
    "    \n",
    "    <font color=\"red\">NOTE: these filters are of your choice, you can explore more options also</font>\n",
    "    \n",
    "    * Example: if your image is of size $(512, 512, 3)$\n",
    "        * the output after $C_1$ will be $128*128*8$\n",
    "        * the output after $C_2$ will be $64*64*16$\n",
    "        * the output after $C_3$ will be $64*64*32$\n",
    "        * the output after $C_4$ will be $64*64*64$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMdxrF6p0bBb"
   },
   "outputs": [],
   "source": [
    "class convolutional_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel=3,  filters=[4,4,8], stride=1, name=\"conv block\"):\n",
    "        super().__init__(name=name)\n",
    "        self.F1, self.F2, self.F3 = filters\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "    def call(self, X):\n",
    "        # write the architecutre that was mentioned above\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZjGHnBf0bBd"
   },
   "outputs": [],
   "source": [
    "class identity_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel=3,  filters=[4,4,8], name=\"identity block\"):\n",
    "        super().__init__(name=name)\n",
    "        self.F1, self.F2, self.F3 = filters\n",
    "        self.kernel = kernel\n",
    "    def call(self, X):\n",
    "        # write the architecutre that was mentioned above\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNP8W_o90bBg"
   },
   "source": [
    "* The output of the $C_4$ will be passed to $\\text{Chained Context Aggregation Module (CAM)}$\n",
    "<img src='https://i.imgur.com/Bu63AAA.png' width=\"400\">\n",
    "* The CAM module will have two operations names Context flow and Global flow\n",
    "* <strong>The Global flow</strong>: \n",
    "    * as shown in the above figure first we willl apply  <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D\">global avg pooling</a> which results in (#, 1, 1, number_of_filters) then applying <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization?version=nightly\">BN</a>, <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU\">RELU</a>, $1*1 \\text{ Conv}$ layer sequentially which results a matrix (#, 1, 1, number_of_filters). Finally apply <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> / <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose\">conv2d transpose</a> to make the output same as the input dimensions (#, input_height, input_width, number_of_filters)\n",
    "    * If you use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> then use bilinear pooling as interpolation technique\n",
    "* <strong>The Context flow</strong>: \n",
    "    * as shown in the above figure (c) the context flow will get inputs from two modules `a. C4` `b. From the above flow` \n",
    "    * We will be <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate\">concatinating</a> the both inputs on the last axis.\n",
    "    * After the concatination we will be applying <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D\"> Average pooling </a> which reduces the size of feature map by $N\\times$ times\n",
    "    * In the paper it was mentioned that to apply a group convolutions, but for the assignment we will be applying the simple conv layers with kernel size $(3*3)$\n",
    "    * We are skipping the channel shuffling \n",
    "    * similarly we will be applying a simple conv layers with kernel size $(3*3)$ consider this output is X\n",
    "    * later we will get the Y=(X $\\otimes \\sigma((1\\times1)conv(relu((1\\times1)conv(X))))) \\oplus X$, here $\\oplus$ is elementwise addition and $\\otimes$ is elementwise multiplication\n",
    "    * Finally apply <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> / <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose\">conv2d transpose</a> to make the output same as the input dimensions (#, input_height, input_width, number_of_filters)\n",
    "    * If you use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> then use bilinear pooling as interpolation technique\n",
    "\n",
    "NOTE: here N times reduction and N time increments makes the input and out shape same, you can explore with the N values, you can choose N = 2 or 4\n",
    "\n",
    "* Example with N=2:\n",
    "    * Assume the C4 is of shape (64,64,64) then the shape of GF will be (64,64,32)\n",
    "    * Assume the C4 is of shape (64,64,64) and the shape of GF is (64,64,32) then the shape of CF1 will be (64,64,32)\n",
    "    * Assume the C4 is of shape (64,64,64) and the shape of CF1 is (64,64,32) then the shape of CF2 will be (64,64,32)\n",
    "    * Assume the C4 is of shape (64,64,64) and the shape of CF2 is (64,64,32) then the shape of CF3 will be (64,64,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2tIIP730bBg"
   },
   "outputs": [],
   "source": [
    "class global_flow(tf.keras.layers.Layer):\n",
    "    def __init__(self, name=\"global_flow\"):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "    def call(self, X):\n",
    "        # implement the global flow operatiom\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oe938KHw0bBk"
   },
   "outputs": [],
   "source": [
    "class context_flow(tf.keras.layers.Layer):    \n",
    "    def __init__(self, name=\"context_flow\"):\n",
    "        super().__init__(name=name)\n",
    "    def call(self, X):\n",
    "        # here X will a list of two elements \n",
    "        INP, FLOW = X[0], X[1] \n",
    "        # implement the context flow as mentioned in the above cell\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZyxvYZp0bBm"
   },
   "source": [
    "* As shown in the above architecture we will be having 4 context flows\n",
    "* if you have implemented correctly all the shapes of Global Flow, and 3 context flows will have the same dimension\n",
    "* the output of these 4 modules will be <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add\">added</a> to get the same output matrix\n",
    "<img src='https://i.imgur.com/Bu63AAA.png' width=\"400\">\n",
    " * The output of after the sum, will be sent to the <strong>Feature selection module $FSM$</strong>\n",
    " \n",
    "* Example:\n",
    "    * if the shapes of GF, CF1, CF2, CF3 are (64,64,32), (64,64,32), (64,64,32), (64,64,32), (64,64,32) respectivly then after the sum we will be getting (64,64,32), which will be passed to the next module.\n",
    " \n",
    "<strong>Feature selection module</strong>:\n",
    "\n",
    "* As part of the FSM we will be applying a conv layer (3,3) with the padding=\"same\" so that the output and input will have same shapes\n",
    "* Let call the output as X\n",
    "* Pass the X to global pooling which results the matrix (#, 1, 1, number_of_channels)\n",
    "* Apply $1*1$ conv layer, after the pooling\n",
    "* the output of the $1*1$ conv layer will be passed to the Batch normalization layer, followed by Sigmoid activation function.\n",
    "* we will be having the output matrix of shape (#, 1, 1, number_of_channels) lets call it 'Y'\n",
    "* <strong>we can interpret this as attention mechanisum, i.e for each channel we will having a weight</strong>\n",
    "* the dimension of X (#, w, h, k) and output above steps Y is (#, 1, 1, k) i.e we need to multiply each channel of X will be <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Multiply\">multiplied</a> with corresponding channel of Y\n",
    "* After creating the weighted channel map we will be doing upsampling such that it will double the height and width.\n",
    "* apply <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> with bilinear pooling as interpolation technique\n",
    "\n",
    "* <font color=\"red\">Example</font>:\n",
    "    * Assume the matrix shape of the input is (64,64,32) then after upsampling it will be (128,128,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNB8srLR0bBn"
   },
   "outputs": [],
   "source": [
    "class fsm(tf.keras.layers.Layer):    \n",
    "    def __init__(self, name=\"feature_selection\"):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "    def call(self, X):\n",
    "        # implement the FSM modules based on image in the above cells\n",
    "        return FSM_Conv_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Xoqx8w50bBp"
   },
   "source": [
    "* <b>Adapted Global Convolutional Network (AGCN)</b>:\n",
    "    <img src=\"https://i.imgur.com/QNB8RmV.png\" width=\"300\">\n",
    "    \n",
    "    * AGCN will get the input from the output of the \"conv block\" of $C_1$\n",
    "    \n",
    "    * In all the above layers we will be using the padding=\"same\" and stride=(1,1)\n",
    "    \n",
    "    * so that we can have the input and output matrices of same size\n",
    "    \n",
    "* <font color=\"red\">Example</font>:\n",
    "    * Assume the matrix shape of the input is (128,128,32) then the output it will be (128,128,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dL_T1Muv0bBq"
   },
   "outputs": [],
   "source": [
    "class agcn(tf.keras.layers.Layer):    \n",
    "    def __init__(self, name=\"global_conv_net\"):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "    def call(self, X):\n",
    "        # please implement the above mentioned architecture\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RStu3wwZ0bBs"
   },
   "source": [
    "*     <img src='https://i.imgur.com/prH3Mno.png' width=\"600\">\n",
    "* as shown in the architecture, after we get the AGCN it will get concatinated with the FSM output\n",
    "\n",
    "* If we observe the shapes both AGCN and FSM will have same height and weight\n",
    "\n",
    "* we will be concatinating both these outputs over the last axis\n",
    "\n",
    "* The concatinated output will be passed to a conv layers with filters = number of classes in our data set and the activation function = 'relu'\n",
    "\n",
    "* we will be using padding=\"same\" which results in the same size feature map\n",
    "\n",
    "* If you observe the shape of matrix, it will be 4x times less than the original image\n",
    "\n",
    "* to make it equal to the original output shape, we will do 4x times upsampling of rows and columns\n",
    "\n",
    "* apply <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> with bilinear pooling as interpolation technique\n",
    "\n",
    "* Finally we will be applying sigmoid activation.\n",
    "\n",
    "* Example:\n",
    "    * Assume the matrix shape of AGCN is (128,128,32)  and FSM is (128,128,32) the concatination will make it (128, 128, 64)\n",
    "    * Applying conv layer will make it (128,128,21)\n",
    "    * Finally applying upsampling will make it (512, 512, 21)\n",
    "    * Applying sigmoid will result in the same matrix (512, 512, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O16er1Nx0bBs"
   },
   "outputs": [],
   "source": [
    "X_input = Input(shape=(128,128,3))\n",
    "\n",
    "# Stage 1\n",
    "X = Conv2D(64, (3, 3), name='conv1', padding=\"same\", kernel_initializer=glorot_uniform(seed=0))(X_input)\n",
    "X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "X = Activation('relu')(X)\n",
    "X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTOD_qPA0bBv"
   },
   "source": [
    "* If you observe the arcitecture we are creating a feature map with 2x time less width and height\n",
    "* we have written the first stage of the code above.\n",
    "* Write the next layers by using the custom layers we have written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UwfJ2tw0bBv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write the complete architecutre\n",
    "\n",
    "model = Model(inputs = X, outputs = output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9Cmyohz0bBz"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, to_file='model4.png', show_shapes=True, show_layer_names=True,\n",
    "    rankdir='TB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXnPVQHw0bB1"
   },
   "source": [
    "### Usefull tips:\n",
    "* use \"interpolation=cv2.INTER_NEAREST\" when you are resizing the image, so that it won't mess with the number of classes\n",
    "* keep the images in the square shape like $256*256$ or $512*512$\n",
    "* Carefull when you are converting the (W, H) output image into (W, H, Classes)\n",
    "* Even for the canet, use the segmentation model's losses and the metrics\n",
    "* The goal of this assignment is make you familier in with computer vision problems, image preprocessing, building complex architectures and implementing research papers, so that in future you will be very confident in industry\n",
    "* you can use the tensorboard logss to see how is yours model's training happening\n",
    "* use callbacks that you have implemented in previous assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHWYBsLz3pRY"
   },
   "source": [
    "### Things to keep in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fr7X4N0v1KlO"
   },
   "source": [
    "* You need to train  above built model and plot the train and test losses.\n",
    "* Make sure there is no overfitting, you are free play with the identity blocks in C1, C2, C3, C4\n",
    "* before we apply the final sigmoid activation, you can add more conv layers or BN or dropouts etc\n",
    "* you are free to use any other optimizer or learning rate or weights init or regularizations"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Segmentation_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
