{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5G7ugMJtOMWw"
   },
   "source": [
    "<h1> <font color='red'> DO read all the comments in the python code and contents in the markdown cells</font> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNLBT5GUbQUN"
   },
   "source": [
    "<pre><font size=4><b>\n",
    "You can do this assignment in google colab itself. we have provided a notebook to use tensorboard in google colab itself.</b></font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "executionInfo": {
     "elapsed": 2665,
     "status": "ok",
     "timestamp": 1576831843984,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDxYhGxtv2B1V63cEKlB91nfsv0JJZBMP1XYabi=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "gjzTYtr1OMW3",
    "outputId": "9f01b3dc-342d-4448-f97e-666fad397547"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#enabled to get instant output. if you don't need, you can use session concept which was dicussed in lecture videos. \n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 967,
     "status": "ok",
     "timestamp": 1576832296022,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDxYhGxtv2B1V63cEKlB91nfsv0JJZBMP1XYabi=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "3rOqYAusgIhU",
    "outputId": "d0df2b7e-4cd8-4307-f936-4c141aa35fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8, 2, 64)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(1000,8,1,64))\n",
    "b = tf.random.uniform(shape=(1000,8,1,64))\n",
    "add = tf.concat([a,b], 2)\n",
    "print(add.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0WP3DUvOMW_"
   },
   "source": [
    "## 1.1 Addition\n",
    "<pre> It is similar to numpy addition.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "executionInfo": {
     "elapsed": 2690,
     "status": "ok",
     "timestamp": 1575182014067,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDxYhGxtv2B1V63cEKlB91nfsv0JJZBMP1XYabi=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "qcKl2W9qOMXC",
    "outputId": "36f8bb88-cd28-4335-a2df-93a31d1619de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.7360089  0.84721303]\n",
      " [0.4983827  0.88693964]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(2,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "executionInfo": {
     "elapsed": 4064,
     "status": "ok",
     "timestamp": 1575182017985,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDxYhGxtv2B1V63cEKlB91nfsv0JJZBMP1XYabi=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "COUVYv5BOMXO",
    "outputId": "de776902-5791-49b3-9840-87965d472f41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=29, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.9188484 , 0.7053194 ],\n",
       "       [0.9889201 , 0.34942663]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.random.uniform(shape=(2,2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7I1KMCgiOMXV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1.6548573, 1.5525324],\n",
       "       [1.4873028, 1.2363663]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add = a + b\n",
    "add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPxWE4stOMXe"
   },
   "source": [
    "<pre> *Broadcasting works similar to numpy.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LIaJTqAwOMXr",
    "outputId": "c510312e-78e7-45d0-d40d-52780d62b18c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=32, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2.736009 , 2.847213 ],\n",
       "       [2.4983826, 2.8869395]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 2.0\n",
    "add_2 = a + c\n",
    "add_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rOJ8iYoOMXw"
   },
   "source": [
    "## 1.2 Subtraction\n",
    "<pre> It is similar to numpy Subtraction.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "x8o22IU7OMXy",
    "outputId": "9bfb179f-8fad-4ef5-cdc6-7b918e37ac6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.2679063   0.05966103]\n",
      " [-0.63556457 -0.01156497]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(2,2))\n",
    "b = tf.random.uniform(shape=(2,2))\n",
    "\n",
    "sub = a - b\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fjRvsmIOMYG"
   },
   "source": [
    "## 1.3 Multiplication\n",
    "<pre>\n",
    "- For two dimensional matrices, you can multiply (m*n) and (n*p) and get (m*p)\n",
    "- for 3 dim matrices, you can multiply (b * n * p)  and (b * p * m)  and get (b * n * m). ( for any dim, you have to maintain last 2 dim as two dim multiplication and first n-2 dim has to be same. you will get better idea if you gothrough    all the operation which we have written below.)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4PKZKq6COMYP",
    "outputId": "858e7e21-e17e-486d-8089-d56ac69f356f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.23157437 0.5690954  0.14154056 0.32255307]\n",
      " [0.26479685 0.28327352 0.2845155  0.15851896]\n",
      " [0.17228022 0.5094883  0.07655424 0.2892458 ]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "b = tf.random.uniform(shape=(2,4))\n",
    "\n",
    "print(tf.matmul(a, b))    # (3*2)x(2*4) = (3*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYtPMQCFOMYV"
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx21Dbw3OMYY"
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SKVwmcKROMYY",
    "outputId": "91d8271f-1792-4f19-8997-785831f47032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.19579867 0.7836783  0.30104357]\n",
      "  [1.0939901  1.4135793  1.010781  ]]\n",
      "\n",
      " [[0.57866657 0.933669   0.93536264]\n",
      "  [0.7614578  0.30989996 1.1445031 ]]\n",
      "\n",
      " [[1.3196485  1.4838941  0.64783084]\n",
      "  [1.612644   1.69175    0.8821995 ]]], shape=(3, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2,4))\n",
    "b = tf.random.uniform(shape=(3,4,3))\n",
    "\n",
    "print(tf.matmul(a, b))   #(3*2*4)x(3*4*3) = (3*2*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYmcWP5fOMYj"
   },
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzrmujBNOMYm"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "c8OvUeISOMYp",
    "outputId": "ba7ecb53-eaf5-4661-e773-afa56b29fc21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.24006644 0.15903112 0.24399412 0.04821377 0.12039072]\n",
      "   [1.6884617  1.0560721  1.7382333  0.7933808  1.0203505 ]]\n",
      "\n",
      "  [[0.6996372  1.5450972  2.0260134  0.73374504 1.596864  ]\n",
      "   [0.67126834 1.7384596  2.0148442  0.8261492  1.3718603 ]]]\n",
      "\n",
      "\n",
      " [[[1.8439484  2.3190572  1.446841   1.3942859  1.8443081 ]\n",
      "   [0.89247406 1.0259893  0.81209946 0.68989646 0.668697  ]]\n",
      "\n",
      "  [[1.0276078  1.2423011  0.958511   0.98299706 1.2850108 ]\n",
      "   [1.2667023  1.5755293  1.0761452  1.0406251  1.1700451 ]]]\n",
      "\n",
      "\n",
      " [[[1.3710663  0.8027344  0.7463181  0.7485063  1.1706581 ]\n",
      "   [0.6769228  0.5601743  0.51034915 0.4491482  0.8350041 ]]\n",
      "\n",
      "  [[1.8773453  1.0436132  0.87168425 1.5936178  0.91715544]\n",
      "   [1.5833329  1.4637746  0.83226115 1.7394497  0.65485024]]]], shape=(3, 2, 2, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2,2,4))\n",
    "b = tf.random.uniform(shape=(3,2,4,5))\n",
    "\n",
    "print(tf.matmul(a,b))    # (3*2*2*4)@(3*2*4*3)=(3*2*2*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhFWsCP1OMY0"
   },
   "source": [
    "## 1. 4 Transpose\n",
    "<pre>    - matrix transpose. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "chFxqDYUOMY0",
    "outputId": "8f695cd4-a9fa-4e36-9775-6f13dad25ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.7225243 0.7158705]\n",
      " [0.8004776 0.2679659]\n",
      " [0.7629862 0.3416741]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2qoOVv8pOMY9",
    "outputId": "9e01e07a-026e-499e-ac90-781bd8edd78e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.7225243 0.8004776 0.7629862]\n",
      " [0.7158705 0.2679659 0.3416741]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.transpose(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwTCIpAQOMZA"
   },
   "source": [
    "<pre>We have a \"perm\" argument for transpose function, in that you can define your own way to change rows and column positions. as shown below</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "iMyw2YIAOMZB",
    "outputId": "62093672-34a0-4f2d-a0db-3c7648ec3485"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2), Dimension(5), Dimension(4)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2,5,4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4K7g_bAsOMZK",
    "outputId": "ef86f009-d814-4b24-cc5b-abee06aa420a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(5), Dimension(2), Dimension(4)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_transpose = tf.transpose(a, perm=[0, 2, 1, 3])\n",
    "a_transpose.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmDQktLGOMZO"
   },
   "source": [
    "<pre>My transposed matrix dim changed based on perm values( we transposed 1 and 2 axis only). you can check below example in that we chnaged all the axis</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pD1ytjz0OMZP",
    "outputId": "b2acaecd-9ef3-4263-9eca-c8f91958cbfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2), Dimension(5), Dimension(4)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2,5,4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rbcCTZuiOMZU",
    "outputId": "9d0c0432-706c-4b04-c0bb-fab83d6192ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(5), Dimension(2), Dimension(3)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_transpose = tf.transpose(a, perm=[3, 2, 1, 0])\n",
    "a_transpose.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_galZ10JOMZX"
   },
   "source": [
    "## 1. 4 Element wise operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luaCDJ_8OMZY"
   },
   "source": [
    "### 1.4.1 Multiply Respective elements in two matrices\n",
    "Ex: \n",
    "<pre>\n",
    "A = [[1 2],\n",
    "     [3,4]]\n",
    "\n",
    "B = [[5,6],\n",
    "     [7,8]]\n",
    "\n",
    "we want A*B as \n",
    "[A[0][0]*B[0][0], A[0][1]*B[0][1]\n",
    "A[1][0]*B[1][0], A[1][1]*B[1][1]]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rIOB8zyIOMZZ",
    "outputId": "3ec7c53e-9347-4950-8359-443895d507b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.2413158  0.0997288 ]\n",
      " [0.13115671 0.59481984]\n",
      " [0.235308   0.07562014]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "b = tf.random.uniform(shape=(3,2))\n",
    "\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "PLWk8lQkOMZg",
    "outputId": "7e4d4b95-e10e-48a2-e123-5ac3b5ada568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.2413158  0.0997288 ]\n",
      " [0.13115671 0.59481984]\n",
      " [0.235308   0.07562014]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.multiply(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.matmul(a,b)** --> matrix multiplication<br>\n",
    "**tf.multiply(a,b)**   OR   **a*b** --> element wise matrix multiplication<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8dLCOEaOMZj"
   },
   "source": [
    "## 1.5 Expanding Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "YfcxwikXOMZq",
    "outputId": "b735dccc-a254-47b9-9ee0-c0077237deb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a_add = tf.expand_dims(a, axis=1)   #we are adding an additional axis at 1st dim\n",
    "\n",
    "print(a_add.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16tS1mknOMZu"
   },
   "source": [
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t28TsjlQOMZv"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "fc4R99CxOMZ2",
    "outputId": "fbb6308d-198b-4437-af9d-1afb3d2c6b72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(2), Dimension(1)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a_add = tf.expand_dims(a, axis=2)#we are adding an additional axis at 2nd dim\n",
    "a_add.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQayeY4wOMZ5"
   },
   "source": [
    "## 1.6 Squeezing dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVomMzI6OMZ6"
   },
   "source": [
    "<pre>\n",
    "Note that we can squeeze along with the axis with shape 1\n",
    "\n",
    "Ex: \n",
    "A.shape= [3,4,1] ==> we can squeez it on axis=2 will give [3,4]\n",
    "A.shape= [3,1,4] ==> we can squeez it on axis=1 will give [3,4]\n",
    "A.shape= [1,3,4] ==> we can squeez it on axis=0 will give [3,4]\n",
    "A.shape= [2,3,4] ==> we can't squeez it on any of the axis\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FYqN12oiOMZ9",
    "outputId": "18ea673d-f869-4d7a-e369-4bcc976cde32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(3,1,4))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "-H6UcJfJOMaA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "a_squ = tf.squeeze(a, axis=1)\n",
    "print(a_squ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SArBwQROMaE"
   },
   "source": [
    "## 1.7 Reshaping of tensors\n",
    "\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/reshape'> check the documentation </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1575182184293,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDxYhGxtv2B1V63cEKlB91nfsv0JJZBMP1XYabi=s64",
      "userId": "00484516897554883881"
     },
     "user_tz": -330
    },
    "id": "wEjdOLJROMaF",
    "outputId": "19bf779c-fe88-4a85-9891-81647f90a99b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 4) (15, 4)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=(5,3,4))\n",
    "\n",
    "# tf.reshape(tensor, [reshape dimensions]])\n",
    "b = tf.reshape(a, [a.shape[0]*a.shape[1], a.shape[2]])\n",
    "\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USHug53cOMaI"
   },
   "source": [
    "# 2. Call Backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "pYFub-clOMaJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Edk77ekZOMaM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# if you observe the input shape is 3D vector, for each image we have a (28*28) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Edk77ekZOMaM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# we will convert the (28*28) vector into single dimensional vector of 1 * 784 \n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) \n",
    "Y_train = tf.keras.utils.to_categorical(y_train, 10) \n",
    "Y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "U6sg7WeVOMaP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_psPfAhOMaR"
   },
   "source": [
    "## 2.1 Writing custom call backs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2zS015yOMaR"
   },
   "source": [
    "<pre>In Keras, Callback is a python class meant to be subclassed to provide specific functionality, <br> with a set of methods called at various stages of training (including batch/epoch start and ends), <br> testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up_jqqGfOMaS"
   },
   "source": [
    "<pre>\n",
    "<b>Writing Call Backs</b> - You can inherit from <b>`tf.keras.callbacks.Callback`</b>,<br> Copied the code for callback class from tensorflow documentation and pased in below cell, you can check that code. <br>It has many methods like batch/epoch_begin/end. so you can do manipulate the model parameters or <br>print the required outputs using these methods.<br> The `logs` dict contains the loss value, and all the metrics at the end of a batch or epoch\n",
    "\n",
    "</pre>\n",
    "> <a href='https://www.w3schools.com/python/python_inheritance.asp'> Do Read this Blog to understand how to inhert other classes </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     2,
     25,
     39,
     42,
     45,
     55,
     66,
     77,
     87,
     98,
     108,
     117,
     125,
     133,
     141,
     149,
     157,
     165
    ],
    "id": "Cv88yZ_pOMaT"
   },
   "outputs": [],
   "source": [
    "class Callback(object):\n",
    "    \n",
    "    \"\"\"Abstract base class used to build new callbacks.\n",
    "      Attributes:\n",
    "          params: dict. Training parameters\n",
    "              (eg. verbosity, batch size, number of epochs...).\n",
    "          model: instance of `keras.models.Model`.\n",
    "              Reference of the model being trained.\n",
    "          validation_data: Deprecated. Do not use.\n",
    "      The `logs` dictionary that callback methods\n",
    "      take as argument will contain keys for quantities relevant to\n",
    "      the current batch or epoch.\n",
    "      Currently, the `.fit()` method of the `Model` class\n",
    "      will include the following quantities in the `logs` that\n",
    "      it passes to its callbacks:\n",
    "          on_epoch_end: logs include `acc` and `loss`, and\n",
    "          optionally include `val_loss`\n",
    "          (if validation is enabled in `fit`), and `val_acc`\n",
    "          (if validation and accuracy monitoring are enabled).\n",
    "          on_batch_begin: logs include `size`,\n",
    "          the number of samples in the current batch.\n",
    "          on_batch_end: logs include `loss`, and optionally `acc`\n",
    "            (if accuracy monitoring is enabled).\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.validation_data = None\n",
    "        self.model = None\n",
    "        # Whether this Callback should only run on the chief worker in a\n",
    "        # Multi-Worker setting.\n",
    "        # TODO(omalleyt): Make this attr public once solution is stable.\n",
    "        self._chief_worker_only = None\n",
    "\n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"Called at the start of an epoch.\n",
    "        Subclasses should override for any actions to run. This function should only\n",
    "        be called during TRAIN mode.\n",
    "        Arguments:\n",
    "            epoch: integer, index of epoch.\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"Called at the end of an epoch.\n",
    "        Subclasses should override for any actions to run. This function should only\n",
    "        be called during TRAIN mode.\n",
    "        Arguments:\n",
    "            epoch: integer, index of epoch.\n",
    "            logs: dict, metric results for this training epoch, and for the\n",
    "              validation epoch if validation is performed. Validation result keys\n",
    "              are prefixed with `val_`.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"Called at the beginning of a training batch in `fit` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
    "              number and the size of the batch.\n",
    "        \"\"\"\n",
    "        # For backwards compatibility.\n",
    "        self.on_batch_begin(batch, logs=logs)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Called at the end of a training batch in `fit` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Metric results for this batch.\n",
    "        \"\"\"\n",
    "        # For backwards compatibility.\n",
    "        self.on_batch_end(batch, logs=logs)\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n",
    "        Also called at the beginning of a validation batch in the `fit`\n",
    "        methods, if validation data is provided.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
    "                  number and the size of the batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Called at the end of a batch in `evaluate` methods.\n",
    "        Also called at the end of a validation batch in the `fit`\n",
    "        methods, if validation data is provided.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Metric results for this batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"Called at the beginning of a batch in `predict` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
    "                  number and the size of the batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Called at the end of a batch in `predict` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Metric results for this batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"Called at the beginning of training.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "                  but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        \"\"\"Called at the end of training.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "                  but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        \"\"\"Called at the beginning of evaluation or validation.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        \"\"\"Called at the end of evaluation or validation.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_begin(self, logs=None):\n",
    "        \"\"\"Called at the beginning of prediction.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_end(self, logs=None):\n",
    "        \"\"\"Called at the end of prediction.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "pfZUPJ01OMah"
   },
   "outputs": [],
   "source": [
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating an instance varible called history\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        self.history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        ## on end of each epoch, we will get logs and update the self.history dict\n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        self.history['acc'].append(logs.get('acc'))\n",
    "        if logs.get('val_loss', -1) != -1:\n",
    "            self.history['val_loss'].append(logs.get('val_loss'))\n",
    "        if logs.get('val_acc', -1) != -1:\n",
    "            self.history['val_acc'].append(logs.get('val_acc'))\n",
    "            \n",
    "history_own = LossHistory()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzEyvZg-OMaj"
   },
   "source": [
    "> in the above function we have written logs={}, which means the logs is a dictionary and the keys present will the same values that gets printed while you train your model i.e model.fit()\n",
    "<img src='https://i.imgur.com/fAiHfe7.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Ca3J3ySeOMak",
    "outputId": "7c7b689b-4e82-4f62-9cef-9882894ee2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 11s 185us/sample - loss: 1.2537 - acc: 0.5599 - val_loss: 1.0469 - val_acc: 0.6375\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 10s 159us/sample - loss: 0.9878 - acc: 0.6651 - val_loss: 0.8634 - val_acc: 0.7196\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 0.8471 - acc: 0.7181 - val_loss: 0.7730 - val_acc: 0.7476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ec59f52828>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50, activation='sigmoid', kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "\n",
    "#output layer\n",
    "output = Dense(10, activation='softmax', kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "\n",
    "#Callbacks\n",
    "history_own = LossHistory()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks=[history_own])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "5nzuF0OPOMam",
    "outputId": "4c4de85a-6095-4938-e92d-cc83993aad5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2537277482509612, 0.9877785322904586, 0.847067549264431],\n",
       " 'acc': [0.5599167, 0.66515, 0.7180667],\n",
       " 'val_loss': [1.0469432671546937, 0.863353873872757, 0.7729612583637238],\n",
       " 'val_acc': [0.6375, 0.7196, 0.7476]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_own.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riBZE6ZrOMao"
   },
   "source": [
    "<pre><b>Writing the call back to terminate training if loss is 'NaN'</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "cMYmZMVeOMap"
   },
   "outputs": [],
   "source": [
    "class TerminateNaN(tf.keras.callbacks.Callback):\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh4umPy9OMaq"
   },
   "source": [
    "## 2.2 Using tensorflow call backs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv9epZaHOMaq"
   },
   "source": [
    "<pre>There are some callbacks which are implemented in the Tensorflow\n",
    "\n",
    "<b>ModelCheckpoint</b> - Save the model after every epoch. You can check documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\">here</a></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "OvIlgI2ROMas"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "h3-DSrb2OMau",
    "outputId": "0f12e82c-e169-4cd0-bf8a-c938384dfae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "59824/60000 [============================>.] - ETA: 0s - loss: 1.2976 - acc: 0.5350\n",
      "Epoch 00001: val_loss improved from inf to 1.19268, saving model to model_save/weights-01-0.5847.hdf5\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: 1.2974 - acc: 0.5350 - val_loss: 1.1927 - val_acc: 0.5847\n",
      "Epoch 2/5\n",
      "59552/60000 [============================>.] - ETA: 0s - loss: 1.1049 - acc: 0.6157\n",
      "Epoch 00002: val_loss improved from 1.19268 to 1.03152, saving model to model_save/weights-02-0.6371.hdf5\n",
      "60000/60000 [==============================] - 9s 153us/sample - loss: 1.1056 - acc: 0.6156 - val_loss: 1.0315 - val_acc: 0.6371\n",
      "Epoch 3/5\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.9628 - acc: 0.6691\n",
      "Epoch 00003: val_loss improved from 1.03152 to 0.88807, saving model to model_save/weights-03-0.6933.hdf5\n",
      "60000/60000 [==============================] - 10s 160us/sample - loss: 0.9626 - acc: 0.6691 - val_loss: 0.8881 - val_acc: 0.6933\n",
      "Epoch 4/5\n",
      "59808/60000 [============================>.] - ETA: 0s - loss: 0.9754 - acc: 0.6631\n",
      "Epoch 00004: val_loss improved from 0.88807 to 0.82620, saving model to model_save/weights-04-0.7335.hdf5\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.9750 - acc: 0.6633 - val_loss: 0.8262 - val_acc: 0.7335\n",
      "Epoch 5/5\n",
      "59664/60000 [============================>.] - ETA: 0s - loss: 0.9230 - acc: 0.6853\n",
      "Epoch 00005: val_loss did not improve from 0.82620\n",
      "60000/60000 [==============================] - 9s 152us/sample - loss: 0.9228 - acc: 0.6854 - val_loss: 0.8809 - val_acc: 0.6885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ec5d6c42e8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "\n",
    "#Callbacks\n",
    "# file path, it saves the model in the 'model_save' folder and we are naming model with epoch number and val acc to \n",
    "# differtiate with other models you have to create model_save folder before running the code.\n",
    "filepath=\"model_save/weights-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=5, validation_data=(X_test,Y_test), batch_size=16, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfAHPmifOMax"
   },
   "source": [
    "<pre>If you need 4th epoch model, you can load that model as below. It saves optimizer state as well. so noo need to recompile. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "r0AIY28BOMaz"
   },
   "outputs": [],
   "source": [
    "model.load_weights('model_save/weights-04-0.7335.hdf5') #change this with your name which you got in above output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "lJ7A1PJHOMa0",
    "outputId": "22cef2e7-19b9-452f-aaad-8ab3618451d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.7834 - acc: 0.7488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ec5d6a2cc0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrHJBrPCOMa3"
   },
   "source": [
    "### 2.2.1 EarlyStopping:\n",
    "\n",
    "<pre>Stop training when a monitored quantity has stopped improving. You can check the documentatin <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\">here</a></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FS1jubUuOMa3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BxU-droOMa6",
    "outputId": "4f77741c-cd29-4173-9d08-5ab8b7ad6a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 1.2376 - acc: 0.5726 - val_loss: 1.1136 - val_acc: 0.6061\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 1.0739 - acc: 0.6299 - val_loss: 1.0187 - val_acc: 0.6332\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12788e695f8>"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "#you can monitor any quantity (here i am monitoring val_loss), you can give any number for patience based on your need. \n",
    "#i am terminating training if my validation loss incresing at once than previous loss. so maintained 1. you can give min delta\n",
    "#an absolute change of less than min_delta, will count as no improvement. i maintained 0.35 because i don't want to run \n",
    "#so many epoch to see termination\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.35, patience=1, verbose=1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=10,validation_data=(X_test,Y_test),batch_size=16,callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05WyP1W2OMa9"
   },
   "source": [
    "<pre>It stopped at 2nd epoch only. You can use this early stopping to get best model than overfitted model</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjQJADh8OMa-"
   },
   "source": [
    "### 2.2.2 LearningRateScheduler:\n",
    "<pre>You can schedule learning rate for every epoch. You can decrease or increase the learning rate based on epoch number. </pre> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "er-L_eZIOMa_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YONlCwyOMbA"
   },
   "outputs": [],
   "source": [
    "def changeLearningRate(epoch):\n",
    "    initial_learningrate=0.1\n",
    "    changed = initial_learningrate*(1-0.1)**epoch\n",
    "    return changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hS18HNhtOMbC"
   },
   "outputs": [],
   "source": [
    "changed_lr = []\n",
    "for i in range(1,50):\n",
    "    changed_lr.append(changeLearningRate(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7JjoQ2aOMbE"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "PSdopgjfOMbG",
    "outputId": "a21ca1de-08c0-4e61-b0af-b0c89075e0ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch number')"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(changed_lr)\n",
    "plt.ylabel('learning_rate')\n",
    "plt.xlabel('epoch number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSvB3InnOMbH"
   },
   "source": [
    "<pre>If you check above figure, learning rate is decreasing if my epoch number is increasing. I am using same function to schedule our learning rate based on epoch number. You can write your own function or you can write custom call back to decrease the learning rate based on val_loss/acc. \n",
    "In the above function, i have implemented exponential decay with decay rate 0.1, you can check that <a href=\"https://mathbitsnotebook.com/Algebra2/Exponential/EXGrowthDecay.html\">here</a></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTZCQXQ_OMbH",
    "outputId": "fc89d5ee-2db1-4376-bade-053be24b01de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 2.2956 - acc: 0.2322 - val_loss: 2.2749 - val_acc: 0.2102\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.09000000000000001.\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 2.2836 - acc: 0.2194 - val_loss: 2.6771 - val_acc: 0.1860\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.08100000000000002.\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 2.2459 - acc: 0.2300 - val_loss: 2.3672 - val_acc: 0.2143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1278ab872e8>"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "# -----------------------------------------------\n",
    "def changeLearningRate(epoch):\n",
    "    initial_learningrate=0.1\n",
    "    changed = initial_learningrate*(1-0.1)**epoch\n",
    "    return changed\n",
    "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)\n",
    "# --------------------------------------------------\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks=[lrschedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVm_fKElOMbK"
   },
   "source": [
    "### 2.2.3 ReduceLROnPlateau\n",
    "<pre>It is similar to EarlyStopping, you can reduce your Learning rate by some factor if my val_loss/acc is not improving. You can check the documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\">here</a></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V35jamIuOMbL"
   },
   "source": [
    "<pre>There are many pre built call backs are available in Tensorflow, you can check those in <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\">this</a> link.\n",
    "\n",
    "You can give as many callbacks you want while training the model as given below.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ts8yx-dwOMbO",
    "outputId": "a841d5e3-0b9f-4916-b35e-8a98337b8c79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
      "Epoch 1/5\n",
      "59808/60000 [============================>.] - ETA: 0s - loss: 2.4306 - acc: 0.1654\n",
      "Epoch 00001: val_loss improved from inf to 2.46765, saving model to model_save/weights-01-0.1518.hdf5\n",
      "60000/60000 [==============================] - 9s 145us/sample - loss: 2.4306 - acc: 0.1654 - val_loss: 2.4676 - val_acc: 0.1518\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.09000000000000001.\n",
      "Epoch 2/5\n",
      "59808/60000 [============================>.] - ETA: 0s - loss: 2.4636 - acc: 0.1512\n",
      "Epoch 00002: val_loss did not improve from 2.46765\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 2.4636 - acc: 0.1511 - val_loss: 2.4743 - val_acc: 0.0984\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1278b151e10>"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "#create a call back list\n",
    "lrschedule = LearningRateScheduler(changeLearningRate, verbose=0.1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.25, patience=1, verbose=1)\n",
    "filepath=\"model_save/weights-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')\n",
    "\n",
    "\n",
    "# here we are creating a list with all the callbacks we want\n",
    "callback_list = [lrschedule, earlystop, checkpoint]\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test),batch_size=16,callbacks=callback_list)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0fjRvsmIOMYG",
    "vhFWsCP1OMY0",
    "_galZ10JOMZX",
    "luaCDJ_8OMZY",
    "z8dLCOEaOMZj",
    "OQayeY4wOMZ5",
    "_SArBwQROMaE"
   ],
   "name": "Call_Backs_Reference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
