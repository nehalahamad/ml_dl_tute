{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual +ve</th>\n",
       "      <th>actual -ve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted +ve</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted -ve</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               actual +ve  actual -ve\n",
       "predicted +ve       10000         100\n",
       "predicted -ve           0           0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "data = pd.read_csv('5_a.csv')\n",
    "\n",
    "data['y_pred'] = np.where(data['proba'] < 0.5, 0, 1)\n",
    "\n",
    "tp = len(data[(data.y==1) & (data.y_pred==1)])\n",
    "fp = len(data[(data.y==0) & (data.y_pred==1)])\n",
    "fn = len(data[(data.y==1) & (data.y_pred==0)])\n",
    "tn = len(data[(data.y==0) & (data.y_pred==0)])\n",
    "\n",
    "confusion_matrix = pd.DataFrame([[tp, fp],[fn, tn]], columns=['actual +ve', 'actual -ve'], index=['predicted +ve', 'predicted -ve'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score =  0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "f1_score = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "print('F1 Score = ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10100/10100 [01:01<00:00, 163.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUS Score is:  0.48829900000000004\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def tpr_fpr(data, th):\n",
    "    data['y_pred'] = np.where(data['proba'] < th, 0, 1)\n",
    "    tp = len(data[(data.y==1) & (data.y_pred==1)])\n",
    "    fp = len(data[(data.y==0) & (data.y_pred==1)])\n",
    "    fn = len(data[(data.y==1) & (data.y_pred==0)])\n",
    "    tn = len(data[(data.y==0) & (data.y_pred==0)])\n",
    "    return tp/(tp+fn), fp/(tn+fp)\n",
    "    \n",
    "thresholds = data.proba.unique()\n",
    "thresholds.sort()\n",
    "\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "for th in tqdm(thresholds):\n",
    "    tpr, fpr = tpr_fpr(data, th)\n",
    "    tpr_list.append(tpr)\n",
    "    fpr_list.append(fpr)\n",
    "    \n",
    "# since fpr_list (which will be on x_axis) is in decreasing order, so we need to make it in increasing order\n",
    "tpr_list.reverse()\n",
    "fpr_list.reverse()\n",
    "\n",
    "AUC_Score = np.trapz(np.array(tpr_list), np.array(fpr_list))\n",
    "print('AUS Score is: ', AUC_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9900990099009901\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual +ve</th>\n",
       "      <th>actual -ve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted +ve</th>\n",
       "      <td>55</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted -ve</th>\n",
       "      <td>45</td>\n",
       "      <td>9761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               actual +ve  actual -ve\n",
       "predicted +ve          55         239\n",
       "predicted -ve          45        9761"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "data = pd.read_csv('5_b.csv')\n",
    "\n",
    "data['y_pred'] = np.where(data['proba'] < 0.5, 0, 1)\n",
    "\n",
    "tp = len(data[(data.y==1) & (data.y_pred==1)])\n",
    "fp = len(data[(data.y==0) & (data.y_pred==1)])\n",
    "fn = len(data[(data.y==1) & (data.y_pred==0)])\n",
    "tn = len(data[(data.y==0) & (data.y_pred==0)])\n",
    "\n",
    "confusion_matrix = pd.DataFrame([[tp, fp],[fn, tn]], columns=['actual +ve', 'actual -ve'], index=['predicted +ve', 'predicted -ve'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score =  0.2791878172588833\n"
     ]
    }
   ],
   "source": [
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "f1_score = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "print('F1 Score = ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10100/10100 [01:05<00:00, 153.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUS Score is:  0.9377570000000001\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def tpr_fpr(data, th):\n",
    "    data['y_pred'] = np.where(data['proba'] < th, 0, 1)\n",
    "    tp = len(data[(data.y==1) & (data.y_pred==1)])\n",
    "    fp = len(data[(data.y==0) & (data.y_pred==1)])\n",
    "    fn = len(data[(data.y==1) & (data.y_pred==0)])\n",
    "    tn = len(data[(data.y==0) & (data.y_pred==0)])\n",
    "    return tp/(tp+fn), fp/(tn+fp)\n",
    "    \n",
    "thresholds = data.proba.unique()\n",
    "thresholds.sort()\n",
    "\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "for th in tqdm(thresholds):\n",
    "    tpr, fpr = tpr_fpr(data, th)\n",
    "    tpr_list.append(tpr)\n",
    "    fpr_list.append(fpr)\n",
    "\n",
    "# since fpr_list (which will be on x_axis) is in decreasing order, so we need to make it in increasing order\n",
    "tpr_list.reverse()\n",
    "fpr_list.reverse()\n",
    "\n",
    "AUC_Score = np.trapz(tpr_list, fpr_list)\n",
    "print('AUS Score is: ', AUC_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2791/2791 [00:09<00:00, 292.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold is:  0.2300390278970873\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('5_c.csv')\n",
    "\n",
    "thresholds = data.prob.unique()\n",
    "thresholds.sort()\n",
    "\n",
    "A = []\n",
    "for th in tqdm(thresholds):\n",
    "    data['y_pred'] = np.where(data['prob'] < th, 0, 1)\n",
    "    fp = len(data[(data.y==0) & (data.y_pred==1)])\n",
    "    fn = len(data[(data.y==1) & (data.y_pred==0)])\n",
    "    A.append( 500*fn + 100*fp )\n",
    "    \n",
    "best_th = thresholds[A.index(min(A))]\n",
    "print('Best threshold is: ', best_th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
    "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       y   pred\n",
      "0  101.0  100.0\n",
      "1  120.0  100.0\n",
      "2  131.0  113.0\n",
      "3  164.0  125.0\n",
      "4  154.0  152.0\n",
      "MSE:  177.16569974554707\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('5_d.csv')\n",
    "print(data.head())\n",
    "mse = np.mean((data.y - data.pred)**2)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Modefied\\ Mean\\ Absolute\\ Percentage\\ Error\\ is:\\\\ M\\_MAPE = \\frac{\\sum_{k=1}^N |e_i|}{\\sum_{k=1}^N |a_i|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE:  0.1291202994009687\n"
     ]
    }
   ],
   "source": [
    "mape = np.sum(np.abs(data.y - data.pred)) / np.sum(data.y)\n",
    "print('MAPE: ', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{SS_{res}}{SS_{res} + SS_{reg}}  = 1 - \\frac{\\sum_{i}^n (y_i - f_i)^2}{\\sum_{i}^n (y_i - f_i)^2 + \\sum_{i}^n (y_i - \\bar y)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_square:  0.9581832343320785\n"
     ]
    }
   ],
   "source": [
    "ss_reg = np.sum( (data.y - np.mean(data.y))**2 )\n",
    "ss_res = np.sum( (data.y - data.pred)**2 )\n",
    "ss_tot = ss_reg + ss_res\n",
    "r_square = 1 - (ss_res / ss_tot)\n",
    "print('R_square: ', r_square)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
